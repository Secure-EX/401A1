0.37525,0.437375,0.440125,0.44575,0.449
For the data showed on line 1, there did exist a huge accuracy positive boost between the 1k dataset and the 5k dataset. However, we might expect the increasing curve act like a logarithmic growth in accuracy over training set size (although the accuracy of the 20k dataset is slightly lower than the 15k one). There may be a threshold based on the chosen of the classifier or the purity of dataset that input into the model since the last three datasets: 10k, 15k, 20k have almost the same accuracy value which is about 44%~45%. This phenomenon is called data overfitting. The more training data you feed into the modeled the lower the training error you will get, but the test error will getting larger since the magnitude of coefficients gets larger.
